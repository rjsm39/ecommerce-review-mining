# -*- coding: utf-8 -*-
"""DM_EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kVCVU7nDaldLbi7ix63VEp9km3OkrTJo
"""

from google.colab import drive
drive.mount('/content/drive')

import sys
import os

py_file_location = "/content/drive/MyDrive"
sys.path.append(os.path.abspath(py_file_location))

import pandas as pd 
import numpy as np
#viz
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec 
import seaborn as sns
from wordcloud import WordCloud ,STOPWORDS
from PIL import Image
import matplotlib_venn as venn
#nlp
import string
import re    
import nltk
from nltk.corpus import stopwords
import spacy
from nltk import pos_tag
from nltk.stem.wordnet import WordNetLemmatizer 
from nltk.tokenize import word_tokenize

# Commented out IPython magic to ensure Python compatibility.
#settings
import nltk
nltk.download('stopwords')
start_time=time.time()
color = sns.color_palette()
sns.set_style("dark")
eng_stopwords = set(stopwords.words("english"))
warnings.filterwarnings("ignore")

lem = WordNetLemmatizer()
tokenizer=TweetTokenizer()

# %matplotlib inline

train = pd.read_csv('/content/drive/MyDrive/train.csv')
dev = pd.read_csv('/content/drive/MyDrive/dev.csv')
test = pd.read_csv('/content/drive/MyDrive/test_no_label.csv').drop('label', axis = 1)

sns.countplot(x='rating',hue='label',data=train)

comment_words = ''
stopwords = set(STOPWORDS)
clean=train[train['label']==1]
# iterate through the csv file
for val in clean.review:
     
    # typecaste each val to string
    val = str(val)
 
    # split the value
    tokens = val.split()
     
    # Converts each token into lowercase
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()
     
    comment_words += " ".join(tokens)+" "
 
wordcloud = WordCloud(width = 800, height = 800,
                background_color ='white',
                stopwords = stopwords,
                min_font_size = 10).generate(comment_words)
 
# plot the WordCloud image                      
plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad = 0)

train['count'] = train['review'].str.split().apply(len).value_counts()

train['count'] = train['review'].str.split().str.len()

print (np.mean(train[train['label']==1]['count']))
print (np.mean(train[train['label']==0]['count']))

sns.countplot(x='label',data=train)



